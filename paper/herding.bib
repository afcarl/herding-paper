@inproceedings{KrauseCevher10,
  author    = {Andreas Krause and
               Volkan Cevher},
  title     = {Submodular Dictionary Selection for Sparse Representation},
  booktitle = {ICML},
  year      = {2010},
  pages     = {567-574},
  ee        = {http://www.icml2010.org/papers/366.pdf},
  crossref  = {DBLP:conf/icml/2010},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
@proceedings{DBLP:conf/icml/2010,
  editor    = {Johannes F{\"u}rnkranz and
               Thorsten Joachims},
  title     = {Proceedings of the 27th International Conference on Machine
               Learning (ICML-10), June 21-24, 2010, Haifa, Israel},
  booktitle = {ICML},
  publisher = {Omnipress},
  year      = {2010},
  isbn      = {978-1-60558-907-7},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{CowlesCarlin96,
    abstract = {A critical issue for users of Markov chain Monte Carlo ({MCMC}) methods in applications is how to determine when it is safe to stop sampling and use the samples to estimate characteristics of the distribution of interest. Research into methods of computing theoretical convergence bounds holds promise for the future but to date has yielded relatively little of practical use in applied work. Consequently, most {MCMC} users address the convergence problem by applying diagnostic tools to the output produced by running their samplers. After giving a brief overview of the area, we provide an expository review of 13 convergence diagnostics, describing the theoretical basis and practical implementation of each. We then compare their performance in two simple models and conclude that all of the methods can fail to detect the sorts of convergence failure that they were designed to identify. We thus recommend a combination of strategies aimed at evaluating and accelerating {MCMC} sampler convergence, including applying diagnostic procedures to a small number of parallel chains, monitoring autocorrelations and cross-correlations, and modifying parametrizations or sampling algorithms appropriately. We emphasize, however, that it is not possible to say with certainty that a finite sample from an {MCMC} algorithm is representative of an underlying stationary distribution.},
    author = {Cowles, Mary K. and Carlin, Bradley P.},
    citeulike-article-id = {828986},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2291683},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2291683},
    doi = {10.2307/2291683},
    issn = {01621459},
    journal = {Journal of the American Statistical Association},
    number = {434},
    pages = {883--904},
    posted-at = {2011-08-13 03:47:38},
    priority = {2},
    publisher = {American Statistical Association},
    title = {Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review},
    url = {http://dx.doi.org/10.2307/2291683},
    volume = {91},
    year = {1996}
}
@techreport{minka2000dqr,
  title={{Deriving quadrature rules from Gaussian processes}},
  author={Minka, T. P.},
  year={2000},
  institution={Statistics Department, Carnegie Mellon University},
}


@inproceedings{guestrin1,
 author = {A. Krause and C. Guestrin and A. Gupta and J. Kleinberg},
 title = {Near-optimal sensor placements: Maximizing information while minimizing communication cost},
 booktitle = {Proceedings of the Fifth International Conference on Information Processing in Sensor Networks (IPSN '06)},
 year = {2006},
 pages = {2--10},
 address = {Nashville, Tennessee, USA},
}

@inproceedings{guestrin2,
  author    = {A. Deshpande and C. Guestrin and S. Madden and J. Hellerstein and W. Hong},
  title     = {Model-Driven Data Acquisition in Sensor Networks},
  booktitle = {Proceedings of the Thirtieth International Conference on Very Large Data Bases (VLDB 2004)},
  location  = {Toronto, Canada},
  year      = {2004},
  pages 	= {588--599},
}

@article{MCUnsound,
author ={A. O'Hagan},
title={{Monte Carlo is fundamentally unsound}},
journal = {The Statistician},
pages = {247-249},
volume ={36},
year = {1987},
}

@article{BZHermiteQuadrature,
	author = {A. O'Hagan},
	journal = {Journal of Statistical Planning and Inference},
	pages = {245--260},
	title = {Bayes-{H}ermite Quadrature},
	volume = {29},
	year = {1991},
}

@PhdThesis{osbornebayesian,
  title = {{Bayesian Gaussian Processes for Sequential Prediction, Optimisation and Quadrature}},
  author = {Osborne, M. A.},
  school = {University of Oxford},
  year = {2010},
}

@InCollection{BZMonteCarlo,
  author = 	 {C. E. Rasmussen and Z. Ghahramani},
  title = 	 {{B}ayesian Monte Carlo},
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {MIT Press},
  year = 	 {2003},
  editor = 	 {S. Becker AND K. Obermayer},
  volume = 	 {15},
  address =  {Cambridge, MA},
}

@article{Sriperumbudur2010,
 author = {Sriperumbudur, Bharath K. and Gretton, Arthur and Fukumizu, Kenji and Sch\"{o}lkopf, Bernhard and Lanckriet, Gert R.G.},
 title = {Hilbert Space Embeddings and Metrics on Probability Measures},
 journal = {J. Mach. Learn. Res.},
 volume = {99},
 month = {August},
 year = {2010},
 issn = {1532-4435},
 pages = {1517--1561},
 numpages = {45},
 url = {http://dl.acm.org/citation.cfm?id=1859890.1859901},
 acmid = {1859901},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@inproceedings{Song2008,
 author = {Song, Le and Zhang, Xinhua and Smola, Alex and Gretton, Arthur and Sch\"{o}lkopf, Bernhard},
 title = {Tailoring density estimation via reproducing kernel moment matching},
 booktitle = {Proceedings of the 25th international conference on Machine learning},
 series = {ICML '08},
 year = {2008},
 isbn = {978-1-60558-205-4},
 location = {Helsinki, Finland},
 pages = {992--999},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1390156.1390281},
 doi = {10.1145/1390156.1390281},
 acmid = {1390281},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{chen2010super,
  title={Super-Samples from Kernel Herding},
  author={Chen, Y. and Welling, M. and Smola, A.},
  year={2010},
  organization={UAI},
}

@inproceedings{welling2009herding,
  title={Herding dynamical weights to learn},
  author={Welling, M.},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={1121--1128},
  year={2009},
  organization={ACM},
}

@article{bach2012equivalence,
  title={On the Equivalence between Herding and Conditional Gradient Algorithms},
  author={Bach, F. and Lacoste-Julien, S. and Obozinski, G.},
  journal={Arxiv preprint arXiv:1203.4523},
  year={2012},
}

@article{rasmussen38gaussian,
  title={{Gaussian Processes for Machine Learning}},
  author={Rasmussen, C.E. and Williams, CKI},
  journal={The MIT Press, Cambridge, MA, USA},
  year={2006},
}

